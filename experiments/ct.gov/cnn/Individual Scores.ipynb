{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Scores\n",
    "\n",
    "- Download files containing losses and f1 scores for each of the tasks trained separately\n",
    "- Parse out this information\n",
    "- Plot learning curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Running Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ssh submit64.cs.utexas.edu 'condor_q ebanner'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%store -r pruned_dataset\n",
    "\n",
    "files = pruned_dataset.columns.tolist()\n",
    "\n",
    "for file in files:\n",
    "    !rm -rf /tmp/$file\n",
    "\n",
    "    !scp -r submit64.cs.utexas.edu:scratch/code/cochrane-nlp/experiments/ct.gov/cnn/output/$file /tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Away Empty Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "files = [file for file in files if os.listdir('/tmp/{}'.format(file))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Separate Runs into One File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    outfiles = !ls /tmp/$file/out.*\n",
    "\n",
    "    for outfile in sorted(outfiles):\n",
    "        !cat \"$outfile\" >> /tmp/$file/out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Away Empty Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "files = [file for file in files if os.path.isfile('/tmp/{}/out'.format(file)) and os.stat('/tmp/{}/out'.format(file)).st_size]\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def performance_generator(targets):\n",
    "    \"\"\"Generate performance for each specified target\n",
    "    \n",
    "    Performance includes history of train and validation loss, as well as f1 scores.\n",
    "    \n",
    "    \"\"\"\n",
    "    for target in targets:\n",
    "        val_losses = !grep 'val loss' /tmp/$target/out | cut -d' ' -f 3\n",
    "        val_losses = [float(val_loss) for val_loss in val_losses]\n",
    "\n",
    "        train_losses = !grep -- '- loss' /tmp/$target/out | cut -d' ' -f 4\n",
    "        train_losses = [float(train_loss) for train_loss in train_losses]\n",
    "\n",
    "        f1s = !grep 'f1' /tmp/$target/out | cut -d' ' -f 3\n",
    "        f1s = [float(f1) for f1 in f1s]\n",
    "        \n",
    "        yield target, OrderedDict(train_losses=train_losses, f1s=f1s, val_losses=val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def best_generator():\n",
    "    \"\"\"Yields the best f1 score for each class\"\"\"\n",
    "    \n",
    "    for target, score_dict in performance_generator(files):\n",
    "        yield target, [np.max(score_dict['f1s'])]\n",
    "        \n",
    "besties = dict(best_generator())\n",
    "               \n",
    "if besties:\n",
    "    pd.DataFrame(besties, index=['best_f1']).T.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Learning Curves\n",
    "\n",
    "- Blue - Train loss\n",
    "- Red - Validation loss\n",
    "- Green - f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "performances = performance_generator(files)\n",
    "\n",
    "num_plots = len(files)\n",
    "\n",
    "fig = plt.figure(figsize=(16, num_plots*2))\n",
    "plt.clf()\n",
    "\n",
    "for i, (target, score_dict) in enumerate(performances, start=1):\n",
    "    \n",
    "    axes = fig.add_subplot((num_plots+1)/2, 3, i)\n",
    "\n",
    "    df = pd.DataFrame(score_dict)\n",
    "    df.index.name = 'epochs'\n",
    "    \n",
    "    df.plot(ax=axes, title=target, legend=False)\n",
    "    \n",
    "fig.subplots_adjust(wspace=.35, hspace=.65)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
