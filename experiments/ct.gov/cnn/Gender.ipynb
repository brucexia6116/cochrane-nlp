{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%store -r cnn_model\n",
    "\n",
    "dataset = cnn_model['dataset']\n",
    "\n",
    "abstracts_padded = cnn_model['abstracts_padded']\n",
    "label_map, ys = cnn_model['label_map'], cnn_model['ys']\n",
    "labels = [i for gender, i in label_map.items()]\n",
    "num_classes = cnn_model['num_classes']\n",
    "\n",
    "embeddings = cnn_model['embeddings']\n",
    "word_dim = cnn_model['word_dim']\n",
    "word2idx, idx2word = cnn_model['word2idx'], cnn_model['idx2word']\n",
    "maxlen = cnn_model['maxlen']\n",
    "vocab_size = cnn_model['vocab_size']\n",
    "num_train = cnn_model['num_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "fold = KFold(len(abstracts_padded), n_folds=5, shuffle=True)\n",
    "p = iter(fold)\n",
    "\n",
    "train_idxs, val_idxs = next(p)\n",
    "\n",
    "X_train, ys_train = abstracts_padded[train_idxs], ys[train_idxs]\n",
    "X_val, ys_val = abstracts_padded[val_idxs], ys[val_idxs]\n",
    "\n",
    "num_train, num_val = len(X_train), len(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_filter = 10\n",
    "filter_length = 2\n",
    "hidden_dims = 32\n",
    "nb_epoch = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 468, 10)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=word_dim, weights=[embeddings], input_length=maxlen,\n",
    "                   trainable=False))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length,\n",
    "                        activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=maxlen-1)) # non-maximum suppression\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model.layers[3].input_shape # ensure non-maximum suppression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Balanced Minibatch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def labelidx_generator(ys):\n",
    "    \"\"\"Generate a dict of labels to their indices\"\"\"\n",
    "\n",
    "    for label in labels:\n",
    "        idxs = np.argwhere(ys == label).flatten()\n",
    "        yield (label, idxs)\n",
    "\n",
    "def batch_generator(ys, batch_size, balanced=True):\n",
    "    \"\"\"Yield successive batches for training\n",
    "    \n",
    "    This generator is not meant to be exhausted, but rather called by next().\n",
    "    \n",
    "    Each batch has batch_size/num_classes number of examples from each class\n",
    "    \n",
    "    \"\"\"\n",
    "    assert not batch_size % num_classes\n",
    "    \n",
    "    labels_idxs = dict(labelidx_generator(ys))\n",
    "    \n",
    "    while True:\n",
    "        idxs_lists = [np.random.choice(label_idxs, size=batch_size/num_classes) for label, label_idxs in labels_idxs.items()]\n",
    "        idxs = [idx for idxs_list in idxs_lists for idx in idxs_list] # flatten list\n",
    "        \n",
    "        yield idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minibatch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "example = batch_generator(ys_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(0.4051237106323242, dtype=float32)]\n",
      "Validation accuracy 0.95\n",
      "[array(0.438852995634079, dtype=float32)]\n",
      "[array(0.43335121870040894, dtype=float32)]\n",
      "[array(0.40232330560684204, dtype=float32)]\n",
      "[array(0.39063912630081177, dtype=float32)]\n",
      "[array(0.41058599948883057, dtype=float32)]\n",
      "[array(0.4017609655857086, dtype=float32)]\n",
      "[array(0.3808741867542267, dtype=float32)]\n",
      "[array(0.37839969992637634, dtype=float32)]\n",
      "[array(0.3931059241294861, dtype=float32)]\n",
      "[array(0.3334627151489258, dtype=float32)]\n",
      "Validation accuracy 0.85\n",
      "[array(0.34864750504493713, dtype=float32)]\n",
      "[array(0.38565483689308167, dtype=float32)]\n",
      "[array(0.37495163083076477, dtype=float32)]\n",
      "[array(0.3774726390838623, dtype=float32)]\n",
      "[array(0.37716686725616455, dtype=float32)]\n",
      "[array(0.33516642451286316, dtype=float32)]\n",
      "[array(0.3275122046470642, dtype=float32)]\n",
      "[array(0.35422855615615845, dtype=float32)]\n",
      "[array(0.2770668566226959, dtype=float32)]\n",
      "[array(0.3274974822998047, dtype=float32)]\n",
      "Validation accuracy 0.85\n",
      "[array(0.34021931886672974, dtype=float32)]\n",
      "[array(0.3450896143913269, dtype=float32)]\n",
      "[array(0.31219443678855896, dtype=float32)]\n",
      "[array(0.3319624662399292, dtype=float32)]\n",
      "[array(0.2925926148891449, dtype=float32)]\n",
      "[array(0.31003859639167786, dtype=float32)]\n",
      "[array(0.3208502233028412, dtype=float32)]\n",
      "[array(0.31375500559806824, dtype=float32)]\n",
      "[array(0.28421828150749207, dtype=float32)]\n",
      "[array(0.31012991070747375, dtype=float32)]\n",
      "Validation accuracy 0.9\n",
      "[array(0.2868606150150299, dtype=float32)]\n",
      "[array(0.28466010093688965, dtype=float32)]\n",
      "[array(0.3032500147819519, dtype=float32)]\n",
      "[array(0.3047681748867035, dtype=float32)]\n",
      "[array(0.2696530222892761, dtype=float32)]\n",
      "[array(0.272286981344223, dtype=float32)]\n",
      "[array(0.2771238386631012, dtype=float32)]\n",
      "[array(0.21329642832279205, dtype=float32)]\n",
      "[array(0.310007244348526, dtype=float32)]\n",
      "[array(0.2427223175764084, dtype=float32)]\n",
      "Validation accuracy 0.9\n",
      "[array(0.2519855201244354, dtype=float32)]\n",
      "[array(0.2386723756790161, dtype=float32)]\n",
      "[array(0.20701807737350464, dtype=float32)]\n",
      "[array(0.2258322536945343, dtype=float32)]\n",
      "[array(0.2542177736759186, dtype=float32)]\n",
      "[array(0.22872735559940338, dtype=float32)]\n",
      "[array(0.18759749829769135, dtype=float32)]\n",
      "[array(0.20412690937519073, dtype=float32)]\n",
      "[array(0.24415621161460876, dtype=float32)]\n",
      "[array(0.15952350199222565, dtype=float32)]\n",
      "Validation accuracy 0.85\n",
      "[array(0.2038489282131195, dtype=float32)]\n",
      "[array(0.23503094911575317, dtype=float32)]\n",
      "[array(0.20917753875255585, dtype=float32)]\n",
      "[array(0.19204577803611755, dtype=float32)]\n",
      "[array(0.24952927231788635, dtype=float32)]\n",
      "[array(0.17974179983139038, dtype=float32)]\n",
      "[array(0.22167998552322388, dtype=float32)]\n",
      "[array(0.21674051880836487, dtype=float32)]\n",
      "[array(0.19425912201404572, dtype=float32)]\n",
      "[array(0.1729784607887268, dtype=float32)]\n",
      "Validation accuracy 0.9\n",
      "[array(0.19465789198875427, dtype=float32)]\n",
      "[array(0.18038280308246613, dtype=float32)]\n",
      "[array(0.14474549889564514, dtype=float32)]\n",
      "[array(0.14710010588169098, dtype=float32)]\n",
      "[array(0.19365042448043823, dtype=float32)]\n",
      "[array(0.1536024808883667, dtype=float32)]\n",
      "[array(0.13260239362716675, dtype=float32)]\n",
      "[array(0.14200112223625183, dtype=float32)]\n",
      "[array(0.1468701958656311, dtype=float32)]\n",
      "[array(0.1437554806470871, dtype=float32)]\n",
      "Validation accuracy 0.85\n",
      "[array(0.14915038645267487, dtype=float32)]\n",
      "[array(0.1490013301372528, dtype=float32)]\n",
      "[array(0.14901480078697205, dtype=float32)]\n",
      "[array(0.13202263414859772, dtype=float32)]\n",
      "[array(0.16220885515213013, dtype=float32)]\n",
      "[array(0.1682291477918625, dtype=float32)]\n",
      "[array(0.13038037717342377, dtype=float32)]\n",
      "[array(0.1877773255109787, dtype=float32)]\n",
      "[array(0.14877508580684662, dtype=float32)]\n",
      "[array(0.13788580894470215, dtype=float32)]\n",
      "Validation accuracy 0.9\n",
      "[array(0.1417868435382843, dtype=float32)]\n",
      "[array(0.14449597895145416, dtype=float32)]\n",
      "[array(0.10768995434045792, dtype=float32)]\n",
      "[array(0.16232669353485107, dtype=float32)]\n",
      "[array(0.13717728853225708, dtype=float32)]\n",
      "[array(0.0957876518368721, dtype=float32)]\n",
      "[array(0.096013642847538, dtype=float32)]\n",
      "[array(0.11497364938259125, dtype=float32)]\n",
      "[array(0.10753194987773895, dtype=float32)]\n",
      "[array(0.11245222389698029, dtype=float32)]\n",
      "Validation accuracy 0.85\n",
      "[array(0.1230914369225502, dtype=float32)]\n",
      "[array(0.08293639868497849, dtype=float32)]\n",
      "[array(0.11662717163562775, dtype=float32)]\n",
      "[array(0.11172908544540405, dtype=float32)]\n",
      "[array(0.11177648603916168, dtype=float32)]\n",
      "[array(0.06180289387702942, dtype=float32)]\n",
      "[array(0.11753321439027786, dtype=float32)]\n",
      "[array(0.08826258033514023, dtype=float32)]\n",
      "[array(0.10506575554609299, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    batch = next(example)\n",
    "    \n",
    "    X = X_train[batch]\n",
    "    ys = np.zeros([batch_size, num_classes])\n",
    "    ys[np.arange(batch_size), ys_train[batch]] = 1\n",
    "\n",
    "    print model.train_on_batch(X, ys)\n",
    "    \n",
    "    if not i % 10:\n",
    "        predictions = model.predict(X_val)\n",
    "\n",
    "        ysval_block = np.zeros([num_val, num_classes])\n",
    "        ysval_block[np.arange(num_val), ys_val] = 1\n",
    "\n",
    "        print 'Validation accuracy', np.mean(predictions.argmax(axis=1) == ys_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASUAAAElCAYAAACiZ/R3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fee8012da50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(X_val)\n",
    "\n",
    "ysval_block = np.zeros([num_val, num_classes])\n",
    "ysval_block[np.arange(num_val), ys_val] = 1\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(ys_val, predictions.argmax(axis=1))\n",
    "\n",
    "from support import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Bigrams Which Filters Fire on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'High-grade prostatic intraepithelial neoplasia (HGPIN) is generally regarded as a premalignant lesion that progresses toward prostate cancer. In light of the significant sequelae of prostate cancer treatment, prevention is desirable, and men with HGPIN would be suitable, high-risk subjects. There is in vitro, in vivo, epidemiologic, and human experimental evidence that selenium supplementation may protect against prostate cancer. This article introduces the rationale for, and progress to date, of a double-blind, randomized, placebo-controlled trial of selenium supplementation (200 mug/d in the form of selenomethionine), to prevent the development of prostate cancer among men with HGPIN. The trial, Southwest Oncology Group Protocol 9917, funded by a National Cancer Institute program supporting pivotal prevention trials has registered 537 patients and has randomized >380 to date. Subject accrual is expected to be completed by the fall of 2006, with trial completion in 2009.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.abstract.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798720959281 , of\n",
      "0.774952054591 trial of\n",
      "0.73860536013 fall of\n",
      "0.702400612893 sequelae of\n",
      "0.64464216135 light of\n",
      "0.626040300484 form of\n",
      "0.587058958733 development of\n",
      "0.470331808933 mug/d in\n",
      "0.451012829234 patients and\n",
      "0.447234792295 380 to\n",
      "\n",
      "0.948453019145 High-grade prostatic\n",
      "0.913312044433 against prostate\n",
      "0.767319063236 toward prostate\n",
      "0.740793297183 of prostate\n",
      "0.740793297183 of prostate\n",
      "0.430028549477 with HGPIN\n",
      "0.430028549477 with HGPIN\n",
      "0.424948660743 prostatic intraepithelial\n",
      "0.406655386123 prostate cancer\n",
      "0.406655386123 prostate cancer\n",
      "\n",
      "0.739442128667 prostate cancer\n",
      "0.739442128667 prostate cancer\n",
      "0.739442128667 prostate cancer\n",
      "0.739442128667 prostate cancer\n",
      "0.505323125421 prostatic intraepithelial\n",
      "0.414727436614 HGPIN .\n",
      "0.397632603225 HGPIN would\n",
      "0.352371829526 HGPIN )\n",
      "0.345550896384 cancer .\n",
      "0.345550896384 cancer .\n",
      "\n",
      "0.956685807885 placebo-controlled trial\n",
      "0.909004443632 a double-blind\n",
      "0.705730790525 The trial\n",
      "0.643539490309 , placebo-controlled\n",
      "0.591753288058 , randomized\n",
      "0.579316948324 with trial\n",
      "0.57661772314 has randomized\n",
      "0.551997112956 trial completion\n",
      "0.546103893806 prevention trials\n",
      "0.543555395881 trial ,\n",
      "\n",
      "0.526654810975 prostate cancer\n",
      "0.526654810975 prostate cancer\n",
      "0.526654810975 prostate cancer\n",
      "0.526654810975 prostate cancer\n",
      "0.48542416675 cancer among\n",
      "0.40899002734 among men\n",
      "0.390602487301 intraepithelial neoplasia\n",
      "0.320250171538 and men\n",
      "0.313824454384 , high-risk\n",
      "0.3086864808 against prostate\n",
      "\n",
      "0.64672374313 with HGPIN\n",
      "0.64672374313 with HGPIN\n",
      "0.628160972107 with trial\n",
      "0.495212455675 among men\n",
      "0.418834218343 cancer among\n",
      "0.411622051612 for ,\n",
      "0.405194405882 and men\n",
      "0.33926204289 vivo ,\n",
      "0.310839606297 randomized ,\n",
      "0.309791516035 vitro ,\n",
      "\n",
      "0.514636871916 among men\n",
      "0.445097243263 intraepithelial neoplasia\n",
      "0.441608426803 men with\n",
      "0.441608426803 men with\n",
      "0.379704656892 prostatic intraepithelial\n",
      "0.3107920849 Oncology Group\n",
      "0.3050464677 High-grade prostatic\n",
      "0.298856975331 and men\n",
      "0.291442806324 <MASK> High-grade\n",
      "0.285598813613 neoplasia (\n",
      "\n",
      "0.579543881336 desirable ,\n",
      "0.573085606564 treatment ,\n",
      "0.56568517309 date ,\n",
      "0.528177021704 suitable ,\n",
      "0.524454821065 ) ,\n",
      "0.517763077309 for ,\n",
      "0.5048459364 vivo ,\n",
      "0.456231793122 vitro ,\n",
      "0.453394082446 trial ,\n",
      "0.453276367261 9917 ,\n",
      "\n",
      "0.229486745416 date .\n",
      "0.210450167341 regarded as\n",
      "0.205639730906 trials has\n",
      "0.205371827767 would be\n",
      "0.200976316333 and has\n",
      "0.190981195239 to be\n",
      "0.186323385124 to date\n",
      "0.186323385124 to date\n",
      "0.172231415905 that selenium\n",
      "0.160167501028 There is\n",
      "\n",
      "0.180524000805 trial completion\n",
      "0.179790245518 200 mug/d\n",
      "0.174180922987 cancer treatment\n",
      "0.135943422317 Protocol 9917\n",
      "0.122234239518 prostatic intraepithelial\n",
      "0.120150429138 selenium supplementation\n",
      "0.120150429138 selenium supplementation\n",
      "0.115084055653 completed by\n",
      "0.109311641664 ( 200\n",
      "0.106495777949 , prevention\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filters = model.layers[2].W.eval()\n",
    "filters = np.squeeze(filters)\n",
    "filters = [filter.T for filter in filters]\n",
    "\n",
    "abstract = abstracts_padded[3]\n",
    "\n",
    "def activation_generator(filter):\n",
    "    for w1, w2 in zip(abstract, abstract[1:]):\n",
    "        yield np.sum(embeddings[[w1, w2]] * filter), (w1, w2)\n",
    "        \n",
    "def activations_generator(filters):\n",
    "    for filter in filters:\n",
    "        yield list(activation_generator(filter))\n",
    "        \n",
    "activations = list(activations_generator(filters))\n",
    "\n",
    "for activation in activations:\n",
    "    for score, (w1, w2) in sorted(activation, reverse=True)[:10]:\n",
    "        print score, idx2word[w1], idx2word[w2]\n",
    "        \n",
    "    print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
