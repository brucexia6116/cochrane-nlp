{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%store -r cnn_model\n",
    "\n",
    "dataset = cnn_model['dataset']\n",
    "\n",
    "abstracts_padded = cnn_model['abstracts_padded']\n",
    "label_map, ys = cnn_model['label_map'], cnn_model['ys']\n",
    "labels = [i for gender, i in label_map.items()]\n",
    "num_classes = cnn_model['num_classes']\n",
    "\n",
    "embeddings = cnn_model['embeddings']\n",
    "word_dim = cnn_model['word_dim']\n",
    "word2idx, idx2word = cnn_model['word2idx'], cnn_model['idx2word']\n",
    "maxlen = cnn_model['maxlen']\n",
    "vocab_size = cnn_model['vocab_size']\n",
    "num_train = cnn_model['num_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, ys_train = abstracts_padded, ys\n",
    "\n",
    "num_train = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "fold = KFold(len(abstracts_padded), n_folds=5)\n",
    "p = iter(fold)\n",
    "\n",
    "train_idxs, val_idxs = next(p)\n",
    "\n",
    "X_train, ys_train = abstracts_padded[train_idxs], ys[train_idxs]\n",
    "X_val, ys_val = abstracts_padded[val_idxs], ys[val_idxs]\n",
    "\n",
    "num_train, num_val = len(X_train), len(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_filter = 5\n",
    "filter_length = 2\n",
    "hidden_dims = 32\n",
    "nb_epoch = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=word_dim, weights=[embeddings], input_length=maxlen,\n",
    "                   trainable=False))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length,\n",
    "                        activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=maxlen-1)) # non-maximum suppression\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(hidden_dims))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "model.layers[3].input_shape # ensure non-maximum suppression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions for Generating Minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def labelidx_generator(ys):\n",
    "    \"\"\"Generate a list of lists, where each list contains all the indices corresponding to a class\"\"\"\n",
    "\n",
    "    for label in labels:\n",
    "        idxs = np.argwhere(ys == label).flatten()\n",
    "        yield idxs\n",
    "\n",
    "def batch_generator(ys, batch_size):\n",
    "    \"\"\"Yield successive batches for training\n",
    "    \n",
    "    This generator is not meant to be exhausted, but rather called by next()\n",
    "    \n",
    "    \"\"\"\n",
    "    assert not batch_size % num_classes\n",
    "    \n",
    "    labels_idxs = list(labelidx_generator(ys))\n",
    "    \n",
    "    while True:\n",
    "        idxs_lists = [np.random.choice(label_idxs, size=batch_size/num_classes) for label_idxs in labels_idxs]\n",
    "        idxs = [idx for idxs_list in idxs_lists for idx in idxs_list]\n",
    "        \n",
    "        yield idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(0.5766856670379639, dtype=float32)]\n",
      "Validation accuracy 0.94\n",
      "[array(0.5705587267875671, dtype=float32)]\n",
      "[array(0.5815173983573914, dtype=float32)]\n",
      "[array(0.5725276470184326, dtype=float32)]\n",
      "[array(0.5817862749099731, dtype=float32)]\n",
      "[array(0.5765678286552429, dtype=float32)]\n",
      "[array(0.5860778093338013, dtype=float32)]\n",
      "[array(0.5810268521308899, dtype=float32)]\n",
      "[array(0.5705460906028748, dtype=float32)]\n",
      "[array(0.559622585773468, dtype=float32)]\n",
      "[array(0.573646605014801, dtype=float32)]\n",
      "Validation accuracy 0.95\n",
      "[array(0.5710346102714539, dtype=float32)]\n",
      "[array(0.568739652633667, dtype=float32)]\n",
      "[array(0.5614373683929443, dtype=float32)]\n",
      "[array(0.550750732421875, dtype=float32)]\n",
      "[array(0.5688070058822632, dtype=float32)]\n",
      "[array(0.5472411513328552, dtype=float32)]\n",
      "[array(0.548345685005188, dtype=float32)]\n",
      "[array(0.5563122034072876, dtype=float32)]\n",
      "[array(0.5607635378837585, dtype=float32)]\n",
      "[array(0.570620596408844, dtype=float32)]\n",
      "Validation accuracy 0.96\n",
      "[array(0.5596684217453003, dtype=float32)]\n",
      "[array(0.5664234757423401, dtype=float32)]\n",
      "[array(0.5604305863380432, dtype=float32)]\n",
      "[array(0.5131137371063232, dtype=float32)]\n",
      "[array(0.5563738346099854, dtype=float32)]\n",
      "[array(0.5482488870620728, dtype=float32)]\n",
      "[array(0.5631244778633118, dtype=float32)]\n",
      "[array(0.5622863173484802, dtype=float32)]\n",
      "[array(0.5317546725273132, dtype=float32)]\n",
      "[array(0.543705403804779, dtype=float32)]\n",
      "Validation accuracy 0.95\n",
      "[array(0.5504475235939026, dtype=float32)]\n",
      "[array(0.49479684233665466, dtype=float32)]\n",
      "[array(0.5254703760147095, dtype=float32)]\n",
      "[array(0.5316829681396484, dtype=float32)]\n",
      "[array(0.551761269569397, dtype=float32)]\n",
      "[array(0.5264981985092163, dtype=float32)]\n",
      "[array(0.5467226505279541, dtype=float32)]\n",
      "[array(0.529253363609314, dtype=float32)]\n",
      "[array(0.5320823788642883, dtype=float32)]\n",
      "[array(0.5458544492721558, dtype=float32)]\n",
      "Validation accuracy 0.96\n",
      "[array(0.5467082858085632, dtype=float32)]\n",
      "[array(0.5142778158187866, dtype=float32)]\n",
      "[array(0.5415878295898438, dtype=float32)]\n",
      "[array(0.5462356805801392, dtype=float32)]\n",
      "[array(0.5075570940971375, dtype=float32)]\n",
      "[array(0.5246314406394958, dtype=float32)]\n",
      "[array(0.49315208196640015, dtype=float32)]\n",
      "[array(0.5219790935516357, dtype=float32)]\n",
      "[array(0.5425271391868591, dtype=float32)]\n",
      "[array(0.5091628432273865, dtype=float32)]\n",
      "Validation accuracy 0.96\n",
      "[array(0.5145005583763123, dtype=float32)]\n",
      "[array(0.5018191933631897, dtype=float32)]\n",
      "[array(0.49145767092704773, dtype=float32)]\n",
      "[array(0.5292605757713318, dtype=float32)]\n",
      "[array(0.5187342762947083, dtype=float32)]\n",
      "[array(0.5027241706848145, dtype=float32)]\n",
      "[array(0.4774274528026581, dtype=float32)]\n",
      "[array(0.506775975227356, dtype=float32)]\n",
      "[array(0.48319804668426514, dtype=float32)]\n",
      "[array(0.5029959678649902, dtype=float32)]\n",
      "Validation accuracy 0.95\n",
      "[array(0.5048195123672485, dtype=float32)]\n",
      "[array(0.4848324656486511, dtype=float32)]\n",
      "[array(0.49330928921699524, dtype=float32)]\n",
      "[array(0.4925152659416199, dtype=float32)]\n",
      "[array(0.46875080466270447, dtype=float32)]\n",
      "[array(0.48270660638809204, dtype=float32)]\n",
      "[array(0.48701831698417664, dtype=float32)]\n",
      "[array(0.4678337574005127, dtype=float32)]\n",
      "[array(0.47725364565849304, dtype=float32)]\n",
      "[array(0.49321600794792175, dtype=float32)]\n",
      "Validation accuracy 0.95\n",
      "[array(0.5211189389228821, dtype=float32)]\n",
      "[array(0.47598400712013245, dtype=float32)]\n",
      "[array(0.5148053169250488, dtype=float32)]\n",
      "[array(0.4606347382068634, dtype=float32)]\n",
      "[array(0.47947198152542114, dtype=float32)]\n",
      "[array(0.4636348783969879, dtype=float32)]\n",
      "[array(0.46680748462677, dtype=float32)]\n",
      "[array(0.45440950989723206, dtype=float32)]\n",
      "[array(0.504055917263031, dtype=float32)]\n",
      "[array(0.4769987463951111, dtype=float32)]\n",
      "Validation accuracy 0.98\n",
      "[array(0.4511220157146454, dtype=float32)]\n",
      "[array(0.44188544154167175, dtype=float32)]\n",
      "[array(0.48947012424468994, dtype=float32)]\n",
      "[array(0.4740338623523712, dtype=float32)]\n",
      "[array(0.4505222737789154, dtype=float32)]\n",
      "[array(0.4991658926010132, dtype=float32)]\n",
      "[array(0.4535362124443054, dtype=float32)]\n",
      "[array(0.45763030648231506, dtype=float32)]\n",
      "[array(0.4606226980686188, dtype=float32)]\n",
      "[array(0.4536103308200836, dtype=float32)]\n",
      "Validation accuracy 0.96\n",
      "[array(0.44661086797714233, dtype=float32)]\n",
      "[array(0.4287116527557373, dtype=float32)]\n",
      "[array(0.450071781873703, dtype=float32)]\n",
      "[array(0.46577006578445435, dtype=float32)]\n",
      "[array(0.48083508014678955, dtype=float32)]\n",
      "[array(0.449408620595932, dtype=float32)]\n",
      "[array(0.4228583574295044, dtype=float32)]\n",
      "[array(0.4451564848423004, dtype=float32)]\n",
      "[array(0.44471150636672974, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "\n",
    "example = batch_generator(ys_train, batch_size)\n",
    "\n",
    "for i in range(100):\n",
    "    batch = next(example)\n",
    "    \n",
    "    X = X_train[batch]\n",
    "    ys = np.zeros([batch_size, num_classes])\n",
    "    ys[np.arange(batch_size), ys_train[batch]] = 1\n",
    "\n",
    "    print model.train_on_batch(X, ys)\n",
    "    \n",
    "    if not i % 10:\n",
    "#         predictions = model.predict(X_val)\n",
    "\n",
    "#         ysval_block = np.zeros([num_val, num_classes])\n",
    "#         ysval_block[np.arange(num_val), ys_val] = 1\n",
    "\n",
    "#         print 'Validation accuracy', np.mean(predictions.argmax(axis=1) == ys_val)\n",
    "\n",
    "        predictions = model.predict(X_train)\n",
    "\n",
    "        ystrain_block = np.zeros([num_train, num_classes])\n",
    "        ystrain_block[np.arange(num_train), ys_train] = 1\n",
    "\n",
    "        print 'Validation accuracy', np.mean(predictions.argmax(axis=1) == ys_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Bigrams Which Filters Fire on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'High-grade prostatic intraepithelial neoplasia (HGPIN) is generally regarded as a premalignant lesion that progresses toward prostate cancer. In light of the significant sequelae of prostate cancer treatment, prevention is desirable, and men with HGPIN would be suitable, high-risk subjects. There is in vitro, in vivo, epidemiologic, and human experimental evidence that selenium supplementation may protect against prostate cancer. This article introduces the rationale for, and progress to date, of a double-blind, randomized, placebo-controlled trial of selenium supplementation (200 mug/d in the form of selenomethionine), to prevent the development of prostate cancer among men with HGPIN. The trial, Southwest Oncology Group Protocol 9917, funded by a National Cancer Institute program supporting pivotal prevention trials has registered 537 patients and has randomized >380 to date. Subject accrual is expected to be completed by the fall of 2006, with trial completion in 2009.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.abstract.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.191696263346 a premalignant\n",
      "0.186450032254 ) is\n",
      "0.175216290962 <MASK> High-grade\n",
      "0.147563402171 generally regarded\n",
      "0.13583212792 , with\n",
      "0.131544865071 accrual is\n",
      "0.127488682589 Cancer Institute\n",
      "0.125468068412 as a\n",
      "0.121252249208 to be\n",
      "0.120584162286 a National\n",
      "\n",
      "1.13796707745 537 patients\n",
      "0.517942211254 high-risk subjects\n",
      "0.491557046927 among men\n",
      "0.397863521459 significant sequelae\n",
      "0.379810744895 and men\n",
      "0.319021065859 > 380\n",
      "0.316419756531 registered 537\n",
      "0.274620137653 intraepithelial neoplasia\n",
      "0.262729626166 Group Protocol\n",
      "0.22434247734 200 mug/d\n",
      "\n",
      "0.315147620768 registered 537\n",
      "0.300667027119 2006 ,\n",
      "0.260423278511 is generally\n",
      "0.244999932357 high-risk subjects\n",
      "0.234140123521 9917 ,\n",
      "0.22159237578 prostatic intraepithelial\n",
      "0.209101468584 cancer among\n",
      "0.208085673979 evidence that\n",
      "0.206715391268 significant sequelae\n",
      "0.200033676969 is expected\n",
      "\n",
      "0.296779350679 mug/d in\n",
      "0.274641513498 trials has\n",
      "0.267795878017 subjects .\n",
      "0.237284318822 Protocol 9917\n",
      "0.232917135325 placebo-controlled trial\n",
      "0.215455264121 men with\n",
      "0.215455264121 men with\n",
      "0.210307766973 supplementation may\n",
      "0.202758432209 randomized >\n",
      "0.198505708795 200 mug/d\n",
      "\n",
      "1.15794737211 toward prostate\n",
      "1.09196847926 of prostate\n",
      "1.09196847926 of prostate\n",
      "1.08720737037 against prostate\n",
      "1.04647958511 High-grade prostatic\n",
      "0.814434782394 with HGPIN\n",
      "0.814434782394 with HGPIN\n",
      "0.780915480438 prostate cancer\n",
      "0.780915480438 prostate cancer\n",
      "0.780915480438 prostate cancer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filters = model.layers[1].W.eval()\n",
    "filters = np.squeeze(filters)\n",
    "filters = [filter.T for filter in filters]\n",
    "\n",
    "abstract = abstracts_padded[3]\n",
    "\n",
    "def activation_generator(filter):\n",
    "    for w1, w2 in zip(abstract, abstract[1:]):\n",
    "        yield np.sum(embeddings[[w1, w2]] * filter), (w1, w2)\n",
    "        \n",
    "def activations_generator(filters):\n",
    "    for filter in filters:\n",
    "        yield list(activation_generator(filter))\n",
    "        \n",
    "activations = list(activations_generator(filters))\n",
    "\n",
    "for activation in activations:\n",
    "    for score, (w1, w2) in sorted(activation, reverse=True)[:10]:\n",
    "        print score, idx2word[w1], idx2word[w2]\n",
    "        \n",
    "    print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
