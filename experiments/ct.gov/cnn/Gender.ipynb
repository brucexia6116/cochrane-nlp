{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%store -r cnn_model\n",
    "\n",
    "dataset = cnn_model['dataset']\n",
    "\n",
    "abstracts_padded = cnn_model['abstracts_padded']\n",
    "labels, ys = cnn_model['labels'], cnn_model['ys']\n",
    "num_classes = cnn_model['num_classes']\n",
    "\n",
    "embeddings = cnn_model['embeddings']\n",
    "word_dim = cnn_model['word_dim']\n",
    "word2idx, idx2word = cnn_model['word2idx'], cnn_model['idx2word']\n",
    "maxlen = cnn_model['maxlen']\n",
    "vocab_size = cnn_model['vocab_size']\n",
    "num_train = cnn_model['num_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "fold = KFold(len(abstracts_padded), n_folds=5)\n",
    "p = iter(fold)\n",
    "\n",
    "train_idxs, val_idxs = next(p)\n",
    "\n",
    "X_train, ys_train = abstracts_padded[train_idxs], ys[train_idxs]\n",
    "X_val, ys_val = abstracts_padded[val_idxs], ys[val_idxs]\n",
    "\n",
    "num_train, num_val = len(X_train), len(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_filter = 5\n",
    "filter_length = 2\n",
    "hidden_dims = 32\n",
    "nb_epoch = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/home/ebanner/.anaconda/envs/py27/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=word_dim, weights=[embeddings], input_length=maxlen))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length,\n",
    "                        activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def labelidx_generator(ys):\n",
    "    \"\"\"Generate a list of lists, where each list contains all the indices corresponding to a class\"\"\"\n",
    "\n",
    "    for label in labels:\n",
    "        idxs = np.argwhere(ys == label).flatten()\n",
    "        yield idxs\n",
    "\n",
    "def batch_generator(ys, batch_size):\n",
    "    \"\"\"Yield successive batches for training\n",
    "    \n",
    "    This generator is not meant to be exhausted, but rather called by next()\n",
    "    \n",
    "    \"\"\"\n",
    "    assert not batch_size % num_classes\n",
    "    \n",
    "    labels_idxs = list(labelidx_generator(ys))\n",
    "    \n",
    "    while True:\n",
    "        idxs_lists = [np.random.choice(label_idxs, size=batch_size/num_classes) for label_idxs in labels_idxs]\n",
    "        idxs = [idx for idxs_list in idxs_lists for idx in idxs_list]\n",
    "        \n",
    "        yield idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(0.15675826370716095, dtype=float32)]\n",
      "Validation accuracy 0.797136038186\n",
      "[array(0.28385475277900696, dtype=float32)]\n",
      "[array(0.13814355432987213, dtype=float32)]\n",
      "[array(0.20715422928333282, dtype=float32)]\n",
      "[array(0.28599366545677185, dtype=float32)]\n",
      "[array(0.3846203684806824, dtype=float32)]\n",
      "[array(0.17764458060264587, dtype=float32)]\n",
      "[array(0.3291880786418915, dtype=float32)]\n",
      "[array(0.12966813147068024, dtype=float32)]\n",
      "[array(0.17874804139137268, dtype=float32)]\n",
      "[array(0.17367976903915405, dtype=float32)]\n",
      "Validation accuracy 0.751789976134\n",
      "[array(0.21907272934913635, dtype=float32)]\n",
      "[array(0.24582543969154358, dtype=float32)]\n",
      "[array(0.2880464792251587, dtype=float32)]\n",
      "[array(0.36144405603408813, dtype=float32)]\n",
      "[array(0.17732064425945282, dtype=float32)]\n",
      "[array(0.24093575775623322, dtype=float32)]\n",
      "[array(0.34361809492111206, dtype=float32)]\n",
      "[array(0.3272550404071808, dtype=float32)]\n",
      "[array(0.21755382418632507, dtype=float32)]\n",
      "[array(0.11952842772006989, dtype=float32)]\n",
      "Validation accuracy 0.766109785203\n",
      "[array(0.1661876142024994, dtype=float32)]\n",
      "[array(0.2224099338054657, dtype=float32)]\n",
      "[array(0.14928016066551208, dtype=float32)]\n",
      "[array(0.18140314519405365, dtype=float32)]\n",
      "[array(0.2517787516117096, dtype=float32)]\n",
      "[array(0.22272250056266785, dtype=float32)]\n",
      "[array(0.12284025549888611, dtype=float32)]\n",
      "[array(0.17820905148983002, dtype=float32)]\n",
      "[array(0.4415871202945709, dtype=float32)]\n",
      "[array(0.11068262904882431, dtype=float32)]\n",
      "Validation accuracy 0.73031026253\n",
      "[array(0.19030362367630005, dtype=float32)]\n",
      "[array(0.1272466480731964, dtype=float32)]\n",
      "[array(0.1908377856016159, dtype=float32)]\n",
      "[array(0.16989973187446594, dtype=float32)]\n",
      "[array(0.15463270246982574, dtype=float32)]\n",
      "[array(0.2688499689102173, dtype=float32)]\n",
      "[array(0.18009501695632935, dtype=float32)]\n",
      "[array(0.07892095297574997, dtype=float32)]\n",
      "[array(0.2634890675544739, dtype=float32)]\n",
      "[array(0.20060168206691742, dtype=float32)]\n",
      "Validation accuracy 0.825775656325\n",
      "[array(0.17384116351604462, dtype=float32)]\n",
      "[array(0.09486878663301468, dtype=float32)]\n",
      "[array(0.1663198471069336, dtype=float32)]\n",
      "[array(0.11754067242145538, dtype=float32)]\n",
      "[array(0.15304599702358246, dtype=float32)]\n",
      "[array(0.20351052284240723, dtype=float32)]\n",
      "[array(0.11989541351795197, dtype=float32)]\n",
      "[array(0.1640109121799469, dtype=float32)]\n",
      "[array(0.0890984907746315, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 15\n",
    "\n",
    "example = batch_generator(ys_train, batch_size)\n",
    "\n",
    "for i in range(50):\n",
    "    batch = next(example)\n",
    "    \n",
    "    X = X_train[batch]\n",
    "    ys = np.zeros([batch_size, num_classes])\n",
    "    ys[np.arange(batch_size), ys_train[batch]] = 1\n",
    "\n",
    "    print model.train_on_batch(X, ys)\n",
    "    \n",
    "    if not i % 10:\n",
    "        predictions = model.predict(X_val)\n",
    "\n",
    "        ysval_block = np.zeros([num_val, num_classes])\n",
    "        ysval_block[np.arange(num_val), ys_val] = 1\n",
    "\n",
    "        print 'Validation accuracy', np.mean(predictions.argmax(axis=1) == ys_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Bigrams Which Filters Fire on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50322654533 may be\n",
      "0.474932492351 to treatment\n",
      "0.356489096645 6-month trial\n",
      "0.356489096645 6-month trial\n",
      "0.342796811713 in this\n",
      "0.338289636034 to conventional\n",
      "0.330906883058 in trials\n",
      "0.326156170715 Twenty-six subjects\n",
      "0.324985800699 group design\n",
      "0.315732342744 this trial\n",
      "\n",
      "0.764217942926 weeks ,\n",
      "0.762268309115 double-blind ,\n",
      "0.741424259313 antipsychotics ,\n",
      "0.697436696345 trial ,\n",
      "0.689886737123 symptoms ,\n",
      "0.680677173386 D-Cycloserine ,\n",
      "0.659943370502 agonists ,\n",
      "0.593603398568 rate ,\n",
      "0.573663654616 measures ,\n",
      "0.558188986289 site ,\n",
      "\n",
      "0.710394467062 . Twenty-six\n",
      "0.693357548702 . Fifty-five\n",
      "0.609068424439 . D-Cycloserine\n",
      "0.609068424439 . D-Cycloserine\n",
      "0.608119034006 . The\n",
      "0.607546749587 for 6\n",
      "0.605416647719 . To\n",
      "0.575126949295 . Because\n",
      "0.549679709433 for efficacy\n",
      "0.516910220145 or 24\n",
      "\n",
      "0.499560751384 serum concentrations\n",
      "0.32207013346 D-cycloserine concentrations\n",
      "0.241639645219 . Serum\n",
      "0.230938948244 50 mg/day\n",
      "0.230938948244 50 mg/day\n",
      "0.228223810593 Serum D-cycloserine\n",
      "0.226470604321 were randomly\n",
      "0.226172298852 subjects completed\n",
      "0.22119862646 ; drop-out\n",
      "0.221097644193 agonist at\n",
      "\n",
      "0.727295614031 placebo for\n",
      "0.50069141557 loss of\n",
      "0.457876875268 patients with\n",
      "0.440292680147 weeks ,\n",
      "0.412281396292 months in\n",
      "0.403145351541 augmentation of\n",
      "0.377907717998 weeks duration\n",
      "0.362829351416 range of\n",
      "0.361932007219 placebo treatment\n",
      "0.358470072134 8 or\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filters = model.layers[2].W.eval()\n",
    "filters = np.squeeze(filters)\n",
    "filters = [filter.T for filter in filters]\n",
    "\n",
    "abstract = abstracts_padded[0]\n",
    "\n",
    "def activation_generator(filter):\n",
    "    for w1, w2 in zip(abstract, abstract[1:]):\n",
    "        yield np.sum(embeddings[[w1, w2]] * filter), (w1, w2)\n",
    "        \n",
    "def activations_generator(filters):\n",
    "    for filter in filters:\n",
    "        yield list(activation_generator(filter))\n",
    "        \n",
    "activations = list(activations_generator(filters))\n",
    "\n",
    "for activation in activations:\n",
    "    for score, (w1, w2) in sorted(activation, reverse=True)[:10]:\n",
    "        print score, idx2word[w1], idx2word[w2]\n",
    "        \n",
    "    print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
