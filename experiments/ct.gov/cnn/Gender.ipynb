{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%store -r cnn_model\n",
    "\n",
    "dataset = cnn_model['dataset']\n",
    "\n",
    "abstracts_padded = cnn_model['abstracts_padded']\n",
    "labels = cnn_model['ys']\n",
    "num_classes = cnn_model['num_classes']\n",
    "\n",
    "embeddings = cnn_model['embeddings']\n",
    "word_dim = cnn_model['word_dim']\n",
    "word2idx, idx2word = cnn_model['word2idx'], cnn_model['idx2word']\n",
    "maxlen = cnn_model['maxlen']\n",
    "vocab_size = cnn_model['vocab_size']\n",
    "num_train = cnn_model['num_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "nb_filter = 5\n",
    "filter_length = 2\n",
    "hidden_dims = 32\n",
    "nb_epoch = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=word_dim, weights=[embeddings], input_length=maxlen))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length,\n",
    "                        activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30 samples, validate on 30 samples\n",
      "Epoch 1/35\n",
      "30/30 [==============================] - 0s - loss: 0.6129 - acc: 0.9000 - val_loss: 0.5070 - val_acc: 1.0000\n",
      "Epoch 2/35\n",
      "30/30 [==============================] - 0s - loss: 0.5218 - acc: 0.9000 - val_loss: 0.4646 - val_acc: 1.0000\n",
      "Epoch 3/35\n",
      "30/30 [==============================] - 0s - loss: 0.5364 - acc: 0.9667 - val_loss: 0.4103 - val_acc: 1.0000\n",
      "Epoch 4/35\n",
      "30/30 [==============================] - 0s - loss: 0.3986 - acc: 1.0000 - val_loss: 0.3530 - val_acc: 1.0000\n",
      "Epoch 5/35\n",
      "30/30 [==============================] - 0s - loss: 0.4494 - acc: 0.9000 - val_loss: 0.3546 - val_acc: 1.0000\n",
      "Epoch 6/35\n",
      "30/30 [==============================] - 0s - loss: 0.4401 - acc: 0.9000 - val_loss: 0.3451 - val_acc: 1.0000\n",
      "Epoch 7/35\n",
      "30/30 [==============================] - 0s - loss: 0.3856 - acc: 0.9667 - val_loss: 0.2748 - val_acc: 1.0000\n",
      "Epoch 8/35\n",
      "30/30 [==============================] - 0s - loss: 0.3760 - acc: 0.9333 - val_loss: 0.2323 - val_acc: 1.0000\n",
      "Epoch 9/35\n",
      "30/30 [==============================] - 0s - loss: 0.2747 - acc: 0.9667 - val_loss: 0.2156 - val_acc: 1.0000\n",
      "Epoch 10/35\n",
      "30/30 [==============================] - 0s - loss: 0.2917 - acc: 1.0000 - val_loss: 0.1877 - val_acc: 1.0000\n",
      "Epoch 11/35\n",
      "30/30 [==============================] - 0s - loss: 0.2568 - acc: 1.0000 - val_loss: 0.1661 - val_acc: 1.0000\n",
      "Epoch 12/35\n",
      "30/30 [==============================] - 0s - loss: 0.2593 - acc: 0.9667 - val_loss: 0.1545 - val_acc: 1.0000\n",
      "Epoch 13/35\n",
      "30/30 [==============================] - 0s - loss: 0.2366 - acc: 1.0000 - val_loss: 0.1360 - val_acc: 1.0000\n",
      "Epoch 14/35\n",
      "30/30 [==============================] - 0s - loss: 0.1693 - acc: 1.0000 - val_loss: 0.1161 - val_acc: 1.0000\n",
      "Epoch 15/35\n",
      "30/30 [==============================] - 0s - loss: 0.1598 - acc: 1.0000 - val_loss: 0.1044 - val_acc: 1.0000\n",
      "Epoch 16/35\n",
      "30/30 [==============================] - 0s - loss: 0.1816 - acc: 0.9667 - val_loss: 0.0941 - val_acc: 1.0000\n",
      "Epoch 17/35\n",
      "30/30 [==============================] - 0s - loss: 0.1397 - acc: 1.0000 - val_loss: 0.0958 - val_acc: 1.0000\n",
      "Epoch 18/35\n",
      "30/30 [==============================] - 0s - loss: 0.1428 - acc: 1.0000 - val_loss: 0.0770 - val_acc: 1.0000\n",
      "Epoch 19/35\n",
      "30/30 [==============================] - 0s - loss: 0.0894 - acc: 1.0000 - val_loss: 0.0694 - val_acc: 1.0000\n",
      "Epoch 20/35\n",
      "30/30 [==============================] - 0s - loss: 0.1312 - acc: 0.9667 - val_loss: 0.0729 - val_acc: 1.0000\n",
      "Epoch 21/35\n",
      "30/30 [==============================] - 0s - loss: 0.1666 - acc: 0.9667 - val_loss: 0.0602 - val_acc: 1.0000\n",
      "Epoch 22/35\n",
      "30/30 [==============================] - 0s - loss: 0.1114 - acc: 1.0000 - val_loss: 0.0537 - val_acc: 1.0000\n",
      "Epoch 23/35\n",
      "30/30 [==============================] - 0s - loss: 0.1005 - acc: 1.0000 - val_loss: 0.0475 - val_acc: 1.0000\n",
      "Epoch 24/35\n",
      "30/30 [==============================] - 0s - loss: 0.0839 - acc: 1.0000 - val_loss: 0.0422 - val_acc: 1.0000\n",
      "Epoch 25/35\n",
      "30/30 [==============================] - 0s - loss: 0.0983 - acc: 1.0000 - val_loss: 0.0412 - val_acc: 1.0000\n",
      "Epoch 26/35\n",
      "30/30 [==============================] - 0s - loss: 0.0629 - acc: 1.0000 - val_loss: 0.0353 - val_acc: 1.0000\n",
      "Epoch 27/35\n",
      "30/30 [==============================] - 0s - loss: 0.0794 - acc: 1.0000 - val_loss: 0.0337 - val_acc: 1.0000\n",
      "Epoch 28/35\n",
      "30/30 [==============================] - 0s - loss: 0.0801 - acc: 1.0000 - val_loss: 0.0299 - val_acc: 1.0000\n",
      "Epoch 29/35\n",
      "30/30 [==============================] - 0s - loss: 0.0518 - acc: 1.0000 - val_loss: 0.0259 - val_acc: 1.0000\n",
      "Epoch 30/35\n",
      "30/30 [==============================] - 0s - loss: 0.0509 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 31/35\n",
      "30/30 [==============================] - 0s - loss: 0.0666 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 1.0000\n",
      "Epoch 32/35\n",
      "30/30 [==============================] - 0s - loss: 0.0360 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 1.0000\n",
      "Epoch 33/35\n",
      "30/30 [==============================] - 0s - loss: 0.0838 - acc: 0.9667 - val_loss: 0.0232 - val_acc: 1.0000\n",
      "Epoch 34/35\n",
      "30/30 [==============================] - 0s - loss: 0.0494 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 1.0000\n",
      "Epoch 35/35\n",
      "30/30 [==============================] - 0s - loss: 0.0340 - acc: 1.0000 - val_loss: 0.0163 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f412f9ddbd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = np.zeros([num_train, num_classes])\n",
    "ys[np.arange(num_train), labels] = 1\n",
    "\n",
    "model.fit(abstracts_padded, ys, nb_epoch=nb_epoch, show_accuracy=True, validation_data=(abstracts_padded, ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Bigrams Which Filters Fire on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41949547929 weeks ,\n",
      "0.409910006469 weeks duration\n",
      "0.378183749946 months in\n",
      "0.365053895001 6 months\n",
      "0.361200462159 trial ;\n",
      "0.329211430784 for 6\n",
      "0.328533914876 trial ,\n",
      "0.319058119962 trial .\n",
      "0.305586523088 at 8\n",
      "0.305065498853 time .\n",
      "\n",
      "0.38852793387 reflecting the\n",
      "0.359276913601 of the\n",
      "0.359233449515 . The\n",
      "0.320809936559 symptoms .\n",
      "0.318168784284 . Because\n",
      "0.312273309689 of negative\n",
      "0.312273309689 of negative\n",
      "0.31188495453 with response\n",
      "0.302034817561 in this\n",
      "0.301182087749 response of\n",
      "\n",
      "0.46354862094 of 50\n",
      "0.438458310073 of potential\n",
      "0.433554319179 the selected\n",
      "0.421041743161 the magnitude\n",
      "0.398178848994 of 8\n",
      "0.398099703742 of therapeutic\n",
      "0.398099703742 of therapeutic\n",
      "0.386244117003 of schizophrenia\n",
      "0.373783778498 of conventional\n",
      "0.371321940341 of negative\n",
      "\n",
      "0.279932761905 ; drop-out\n",
      "0.240466662996 in a\n",
      "0.240466662996 in a\n",
      "0.22682281232 from placebo\n",
      "0.220197336066 in this\n",
      "0.21780245975 in trials\n",
      "0.191382448753 exhibit therapeutic\n",
      "0.183748895764 , a\n",
      "0.183748895764 , a\n",
      "0.183748895764 , a\n",
      "\n",
      "0.529802227746 . Twenty-six\n",
      "0.522588716292 . Because\n",
      "0.515763847151 . Fifty-five\n",
      "0.513474480613 in a\n",
      "0.513474480613 in a\n",
      "0.497384769347 . D-Cycloserine\n",
      "0.497384769347 . D-Cycloserine\n",
      "0.495702630098 . The\n",
      "0.456090246345 . To\n",
      "0.435462550213 less .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filters = model.layers[2].W.eval()\n",
    "filters = np.squeeze(filters)\n",
    "filters = [filter.T for filter in filters]\n",
    "\n",
    "abstract = abstracts_padded[0]\n",
    "\n",
    "def activation_generator(filter):\n",
    "    for w1, w2 in zip(abstract, abstract[1:]):\n",
    "        yield np.sum(embeddings[[w1, w2]] * filter), (w1, w2)\n",
    "        \n",
    "def activations_generator(filters):\n",
    "    for filter in filters:\n",
    "        yield list(activation_generator(filter))\n",
    "        \n",
    "activations = list(activations_generator(filters))\n",
    "\n",
    "for activation in activations:\n",
    "    for score, (w1, w2) in sorted(activation, reverse=True)[:10]:\n",
    "        print score, idx2word[w1], idx2word[w2]\n",
    "        \n",
    "    print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
