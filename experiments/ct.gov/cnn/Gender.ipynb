{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%store -r cnn_model\n",
    "\n",
    "dataset = cnn_model['dataset'].reset_index(drop=True)\n",
    "\n",
    "abstracts_padded = cnn_model['abstracts_padded']\n",
    "labels, ys = cnn_model['labels'], cnn_model['ys'].reset_index(drop=True)\n",
    "num_classes = cnn_model['num_classes']\n",
    "\n",
    "embeddings = cnn_model['embeddings']\n",
    "word_dim = cnn_model['word_dim']\n",
    "word2idx, idx2word = cnn_model['word2idx'], cnn_model['idx2word']\n",
    "maxlen = cnn_model['maxlen']\n",
    "vocab_size = cnn_model['vocab_size']\n",
    "num_train = cnn_model['num_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_filter = 5\n",
    "filter_length = 2\n",
    "hidden_dims = 32\n",
    "nb_epoch = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/home/ebanner/.anaconda/envs/py27/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=word_dim, weights=[embeddings], input_length=maxlen))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length,\n",
    "                        activation='relu'))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def labelidx_generator():\n",
    "    \"\"\"Generate a list where each element is all the indexes corresponding to a class\"\"\"\n",
    "\n",
    "    for label in labels:\n",
    "        yield ys[ys == label].index.tolist()\n",
    "\n",
    "def batch_generator(batch_size):\n",
    "    \"\"\"Yield successive batches for training\n",
    "    \n",
    "    This generator is not meant to be exhausted, but rather called by next()\n",
    "    \n",
    "    \"\"\"\n",
    "    assert not batch_size % num_classes\n",
    "    \n",
    "    labels_idxs = list(labelidx_generator())\n",
    "    \n",
    "    while True:\n",
    "        idxs_lists = [np.random.choice(label_idxs, size=batch_size/num_classes) for label_idxs in labels_idxs]\n",
    "        idxs = [idx for idxs_list in idxs_lists for idx in idxs_list]\n",
    "        \n",
    "        yield idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 15\n",
    "\n",
    "example = batch_generator(batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(0.4703173339366913, dtype=float32)]\n",
      "[array(0.30346372723579407, dtype=float32)]\n",
      "[array(0.3935213088989258, dtype=float32)]\n",
      "[array(0.26881158351898193, dtype=float32)]\n",
      "[array(0.4369662404060364, dtype=float32)]\n",
      "[array(0.2765965163707733, dtype=float32)]\n",
      "[array(0.4600931406021118, dtype=float32)]\n",
      "[array(0.46159836649894714, dtype=float32)]\n",
      "[array(0.37763652205467224, dtype=float32)]\n",
      "[array(0.18277865648269653, dtype=float32)]\n",
      "[array(0.203164741396904, dtype=float32)]\n",
      "[array(0.16951055824756622, dtype=float32)]\n",
      "[array(0.5674611330032349, dtype=float32)]\n",
      "[array(0.3887283504009247, dtype=float32)]\n",
      "[array(0.34243258833885193, dtype=float32)]\n",
      "[array(0.4788208305835724, dtype=float32)]\n",
      "[array(0.2791329026222229, dtype=float32)]\n",
      "[array(0.27685075998306274, dtype=float32)]\n",
      "[array(0.3246164619922638, dtype=float32)]\n",
      "[array(0.4835849702358246, dtype=float32)]\n",
      "[array(0.4905903935432434, dtype=float32)]\n",
      "[array(0.31166955828666687, dtype=float32)]\n",
      "[array(0.24679981172084808, dtype=float32)]\n",
      "[array(0.5644682049751282, dtype=float32)]\n",
      "[array(0.4096483886241913, dtype=float32)]\n",
      "[array(0.184075266122818, dtype=float32)]\n",
      "[array(0.3372660279273987, dtype=float32)]\n",
      "[array(0.3094598352909088, dtype=float32)]\n",
      "[array(0.26163944602012634, dtype=float32)]\n",
      "[array(0.38237276673316956, dtype=float32)]\n",
      "[array(0.562578558921814, dtype=float32)]\n",
      "[array(0.4288329482078552, dtype=float32)]\n",
      "[array(0.349863201379776, dtype=float32)]\n",
      "[array(0.25278767943382263, dtype=float32)]\n",
      "[array(0.23905833065509796, dtype=float32)]\n",
      "[array(0.3426743745803833, dtype=float32)]\n",
      "[array(0.20820075273513794, dtype=float32)]\n",
      "[array(0.44589319825172424, dtype=float32)]\n",
      "[array(0.24427300691604614, dtype=float32)]\n",
      "[array(0.08743277192115784, dtype=float32)]\n",
      "[array(0.24270296096801758, dtype=float32)]\n",
      "[array(0.3065527081489563, dtype=float32)]\n",
      "[array(0.3642278015613556, dtype=float32)]\n",
      "[array(0.21986150741577148, dtype=float32)]\n",
      "[array(0.38616079092025757, dtype=float32)]\n",
      "[array(0.3050563931465149, dtype=float32)]\n",
      "[array(0.23759247362613678, dtype=float32)]\n",
      "[array(0.21062365174293518, dtype=float32)]\n",
      "[array(0.3205476999282837, dtype=float32)]\n",
      "[array(0.21736861765384674, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    batch = next(example)\n",
    "\n",
    "    abstracts_batch = abstracts_padded[batch]\n",
    "\n",
    "    batch_size = 15\n",
    "\n",
    "    ys_batch = np.zeros([batch_size, num_classes])\n",
    "    ys_batch[np.arange(batch_size), ys[batch]] = 1\n",
    "\n",
    "    print model.train_on_batch(abstracts_batch, ys_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92546583850931674"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(abstracts_padded)\n",
    "\n",
    "np.mean(predictions.argmax(axis=1) == ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Bigrams Which Filters Fire on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.439572675754 trials of\n",
      "0.351481750361 range of\n",
      "0.342615633999 symptoms of\n",
      "0.318224560524 magnitude of\n",
      "0.318224560524 magnitude of\n",
      "0.317734985361 Serum D-cycloserine\n",
      "0.30851242987 impairment of\n",
      "0.297891491023 trial .\n",
      "0.290294148023 dose of\n",
      "0.279616767301 D-serine .\n",
      "\n",
      "0.786158382607 of the\n",
      "0.758244342999 assess the\n",
      "0.738976918683 for the\n",
      "0.738976918683 for the\n",
      "0.715640993039 reflecting the\n",
      "0.690424686484 completed the\n",
      "0.68217528849 at the\n",
      "0.664111372325 by the\n",
      "0.637346373683 , the\n",
      "0.555191480812 . The\n",
      "\n",
      "0.557287294566 . Fifty-five\n",
      "0.557004542489 . Twenty-six\n",
      "0.402393250002 . The\n",
      "0.365552048554 groups .\n",
      "0.342196002817 patients with\n",
      "0.338112218278 8 or\n",
      "0.335882991987 efficacy for\n",
      "0.335882991987 efficacy for\n",
      "0.332375408683 placebo for\n",
      "0.328273904131 effect for\n",
      "\n",
      "0.545715160704 trial .\n",
      "0.470450553283 design .\n",
      "0.464260040643 schizophrenia .\n",
      "0.429435329372 trials of\n",
      "0.420994493496 in this\n",
      "0.420819714946 in a\n",
      "0.420819714946 in a\n",
      "0.412282548534 antipsychotics in\n",
      "0.412282548534 antipsychotics in\n",
      "0.406762013761 efficacy for\n",
      "\n",
      "0.559193308222 6 months\n",
      "0.493051252256 ; drop-out\n",
      "0.474122846806 8 weeks\n",
      "0.45904877785 at 8\n",
      "0.406568567576 for 6\n",
      "0.39675390469 or 24\n",
      "0.385976582473 24 weeks\n",
      "0.293012326581 50 mg/day\n",
      "0.293012326581 50 mg/day\n",
      "0.272327574567 of 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filters = model.layers[2].W.eval()\n",
    "filters = np.squeeze(filters)\n",
    "filters = [filter.T for filter in filters]\n",
    "\n",
    "abstract = abstracts_padded[0]\n",
    "\n",
    "def activation_generator(filter):\n",
    "    for w1, w2 in zip(abstract, abstract[1:]):\n",
    "        yield np.sum(embeddings[[w1, w2]] * filter), (w1, w2)\n",
    "        \n",
    "def activations_generator(filters):\n",
    "    for filter in filters:\n",
    "        yield list(activation_generator(filter))\n",
    "        \n",
    "activations = list(activations_generator(filters))\n",
    "\n",
    "for activation in activations:\n",
    "    for score, (w1, w2) in sorted(activation, reverse=True)[:10]:\n",
    "        print score, idx2word[w1], idx2word[w2]\n",
    "        \n",
    "    print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
