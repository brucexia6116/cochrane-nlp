{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask Learning\n",
    "\n",
    "Use a single shared representation to predict gender and phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%store -r embeddings_info\n",
    "\n",
    "abstracts = embeddings_info['abstracts']\n",
    "abstracts_padded = embeddings_info['abstracts_padded']\n",
    "embeddings = embeddings_info['embeddings']\n",
    "word_dim = embeddings_info['word_dim']\n",
    "word2idx, idx2word = embeddings_info['word2idx'], embeddings_info['idx2word']\n",
    "maxlen = embeddings_info['maxlen']\n",
    "vocab_size = embeddings_info['vocab_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%store -r pruned_dataset binarized_dataset\n",
    "\n",
    "ys = np.array(binarized_dataset).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, ys_train = abstracts_padded, ys\n",
    "X_val, ys_val = abstracts_padded, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "fold = KFold(len(abstracts_padded), n_folds=5, shuffle=True)\n",
    "p = iter(fold)\n",
    "\n",
    "train_idxs, val_idxs = next(p)\n",
    "\n",
    "X_train, ys_train = abstracts_padded[train_idxs], ys[train_idxs]\n",
    "X_val, ys_val = abstracts_padded[val_idxs], ys[val_idxs]\n",
    "\n",
    "num_train, num_val = len(X_train), len(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_filter = 20\n",
    "filter_length = 2\n",
    "hidden_dims = 32\n",
    "nb_epoch = 35\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "/home/ebanner/.anaconda/envs/py27/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Graph\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "\n",
    "model = Graph()\n",
    "model.add_input(name='input', input_shape=[maxlen], dtype='int') # dtype='int' is 100% necessary for some reason!\n",
    "model.add_node(Embedding(input_dim=vocab_size, output_dim=word_dim, weights=[embeddings], input_length=maxlen, trainable=False),\n",
    "               name='embedding', input='input')\n",
    "model.add_node(Dropout(0.25), name='dropout1', input='embedding')\n",
    "\n",
    "model.add_node(Convolution1D(nb_filter=nb_filter,\n",
    "                             filter_length=filter_length,\n",
    "                             activation='relu'),\n",
    "              name='conv',\n",
    "              input='dropout1')\n",
    "model.add_node(MaxPooling1D(pool_length=maxlen-1), name='pool', input='conv') # non-maximum suppression\n",
    "model.add_node(Flatten(), name='flat', input='pool')\n",
    "model.add_node(Dense(hidden_dims), name='z', input='flat')\n",
    "model.add_node(Activation('relu'), name='shared', input='z')\n",
    "model.add_node(Dropout(0.25), name='dropout2', input='shared')\n",
    "\n",
    "model.add_node(Dense(output_dim=2, activation='softmax'), name='gender_probs', input='dropout2')\n",
    "model.add_output(name='gender', input='gender_probs')\n",
    "\n",
    "model.add_node(Dense(output_dim=2, activation='softmax'), name='phase_2_probs', input='dropout2')\n",
    "model.add_output(name='phase_2', input='phase_2_probs')\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'gender': 'categorical_crossentropy',\n",
    "                    'phase_2': 'categorical_crossentropy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Balanced Minibatch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_generator(ys, batch_size, balanced=True):\n",
    "    \"\"\"Yield successive batches for training\n",
    "    \n",
    "    This generator is not meant to be exhausted, but rather called by next().\n",
    "    \n",
    "    Each batch has batch_size/num_classes number of examples from each class\n",
    "    \n",
    "    \"\"\"\n",
    "    num_objectives, num_train = ys.shape\n",
    "    \n",
    "    while True:\n",
    "        yield np.random.choice(num_train, size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minibatch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_train = len(X_train)\n",
    "\n",
    "batch_size = num_train // 2\n",
    "\n",
    "example = batch_generator(ys_train, batch_size)\n",
    "\n",
    "labels = ['gender', 'phase_2']\n",
    "\n",
    "val_dict = {label: y_row for y_row, label in zip(ys_val, labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(0.48505547642707825, dtype=float32)]\n",
      "gender accuracy: 1.0\n",
      "phase_2 accuracy: 0.9\n",
      "[array(0.31257328391075134, dtype=float32)]\n",
      "gender accuracy: 1.0\n",
      "phase_2 accuracy: 0.9\n",
      "[array(0.3063952624797821, dtype=float32)]\n",
      "gender accuracy: 1.0\n",
      "phase_2 accuracy: 1.0\n",
      "[array(0.37981748580932617, dtype=float32)]\n",
      "gender accuracy: 1.0\n",
      "phase_2 accuracy: 1.0\n",
      "[array(0.22755445539951324, dtype=float32)]\n",
      "gender accuracy: 1.0\n",
      "phase_2 accuracy: 1.0\n",
      "[array(0.26175355911254883, dtype=float32)]\n",
      "gender accuracy: 1.0\n",
      "phase_2 accuracy: 1.0\n",
      "[array(0.422007292509079, dtype=float32)]\n",
      "gender accuracy: 1.0\n",
      "phase_2 accuracy: 1.0\n",
      "[array(0.2125508189201355, dtype=float32)]\n",
      "gender accuracy: 1.0\n",
      "phase_2 accuracy: 1.0\n",
      "[array(0.07638401538133621, dtype=float32)]\n",
      "gender accuracy: 1.0\n",
      "phase_2 accuracy: 1.0\n",
      "[array(0.08776175230741501, dtype=float32)]\n",
      "gender accuracy: 1.0\n",
      "phase_2 accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "def produce_labels(labels, ys, batch_idxs, class_sizes):\n",
    "    batch_size = len(batch_idxs)\n",
    "    \n",
    "    for label, num_classes, y_row in zip(labels, class_sizes, ys):\n",
    "        y_batch = y_row[batch_idxs]\n",
    "        \n",
    "        ys_block = np.zeros([batch_size, num_classes])\n",
    "        ys_block[np.arange(batch_size), y_batch] = 1\n",
    "        \n",
    "        yield (label, ys_block)\n",
    "\n",
    "for i in range(100):\n",
    "    batch_idxs = next(example)\n",
    "    \n",
    "    X = X_train[batch_idxs]\n",
    "    train_dict = dict(produce_labels(labels, ys, batch_idxs, class_sizes=[2, 2]))\n",
    "    train_dict.update({'input': X})\n",
    "\n",
    "    train_error = model.train_on_batch(train_dict)\n",
    "\n",
    "    if not i % 10:\n",
    "        print train_error\n",
    "        \n",
    "        predictions = model.predict({'input': X_val})\n",
    "        for label in labels:\n",
    "            ys_pred = predictions[label]\n",
    "            ys_pred = ys_pred.argmax(axis=1)\n",
    "            \n",
    "            print '{} accuracy:'.format(label), np.mean(ys_pred == val_dict[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_val)\n",
    "\n",
    "ysval_block = np.zeros([num_val, num_classes])\n",
    "ysval_block[np.arange(num_val), ys_val] = 1\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(ys_val, predictions.argmax(axis=1))\n",
    "\n",
    "from support import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(cm, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Bigrams Which Filters Fire on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.abstract.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filters = model.layers[2].W.eval()\n",
    "filters = np.squeeze(filters)\n",
    "filters = [filter.T for filter in filters]\n",
    "\n",
    "def activation_generator(filter, abstract):\n",
    "    for w1, w2 in zip(abstract, abstract[1:]):\n",
    "        yield np.sum(embeddings[[w1, w2]] * filter), (w1, w2)\n",
    "        \n",
    "def activations_generator(filters, abstract):\n",
    "    for filter in filters:\n",
    "        yield list(activation_generator(filter, abstract))\n",
    "        \n",
    "def show_activations(filters, abstract):        \n",
    "    activations = list(activations_generator(filters, abstract))\n",
    "\n",
    "    for activation in activations:\n",
    "        for score, (w1, w2) in sorted(activation, reverse=True)[:10]:\n",
    "            print score, idx2word[w1], idx2word[w2]\n",
    "\n",
    "        print\n",
    "        \n",
    "for gender, idx in zip(['Both', 'Female', 'Male'], [0, 50, 100]):\n",
    "    print '*'*10, gender, '*'*10\n",
    "    show_activations(filters, abstracts_padded[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
